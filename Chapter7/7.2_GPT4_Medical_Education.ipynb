{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.68.2-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\inhag\\.virtualenvs\\chapter7-ohihpsxv\\lib\\site-packages (2.2.3)\n",
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\inhag\\.virtualenvs\\chapter7-ohihpsxv\\lib\\site-packages (4.67.1)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.9.0-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\inhag\\.virtualenvs\\chapter7-ohihpsxv\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\inhag\\.virtualenvs\\chapter7-ohihpsxv\\lib\\site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\inhag\\.virtualenvs\\chapter7-ohihpsxv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\inhag\\.virtualenvs\\chapter7-ohihpsxv\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\inhag\\.virtualenvs\\chapter7-ohihpsxv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\inhag\\.virtualenvs\\chapter7-ohihpsxv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\inhag\\.virtualenvs\\chapter7-ohihpsxv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\inhag\\.virtualenvs\\chapter7-ohihpsxv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.27.2-cp312-cp312-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\inhag\\.virtualenvs\\chapter7-ohihpsxv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading openai-1.68.2-py3-none-any.whl (606 kB)\n",
      "   ---------------------------------------- 0.0/606.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 606.1/606.1 kB 11.1 MB/s eta 0:00:00\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.9.0-cp312-cp312-win_amd64.whl (207 kB)\n",
      "Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 15.7 MB/s eta 0:00:00\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: sniffio, PyPDF2, pydantic-core, jiter, h11, distro, annotated-types, pydantic, httpcore, anyio, httpx, openai\n",
      "Successfully installed PyPDF2-3.0.1 annotated-types-0.7.0 anyio-4.9.0 distro-1.9.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 jiter-0.9.0 openai-1.68.2 pydantic-2.10.6 pydantic-core-2.27.2 sniffio-1.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install openai pandas PyPDF2 tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 코드를 진행하기 위해 OpenAI API 가입 및 결제가 선행되어야 합니다.\n",
    "\n",
    "OpenAI API 가이드에 따라서 API_KEY를 발급 받으신 후 활용하세요.\n",
    "\n",
    "활용 가능한 모델은 [https://platform.openai.com/docs/models](https://platform.openai.com/docs/models) 에서 확인할 수 있습니다.\n",
    "\n",
    "** API key를 발급받으신 후 'Your-OpenAI-Key' 문자열 검색 및 해당 자리에 발급받은 OpenAI-key 키를 넣어주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 07:15:06,549 - INFO - PDFSummarizer 초기화 완료 (모델: o3-mini-2025-01-31)\n",
      "2025-03-25 07:15:06,550 - INFO - 파일 처리 시작: diagnostics-12-02679.pdf\n",
      "2025-03-25 07:15:06,552 - INFO - 파일 처리 시작: ryai.2020200198.pdf\n",
      "2025-03-25 07:15:06,554 - INFO - 파일 처리 시작: s12891-022-05818-4.pdf\n",
      "PDF 요약 진행 중:   0%|          | 0/3 [00:00<?, ?it/s]2025-03-25 07:15:06,933 - INFO - 텍스트가 길어서 청크로 나누어 요약합니다: diagnostics-12-02679.pdf\n",
      "2025-03-25 07:15:07,424 - INFO - 텍스트가 길어서 청크로 나누어 요약합니다: ryai.2020200198.pdf\n",
      "2025-03-25 07:15:07,786 - INFO - 텍스트가 길어서 청크로 나누어 요약합니다: s12891-022-05818-4.pdf\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 로깅 설정\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"pdf_summarizer.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger()\n",
    "\n",
    "class PDFSummarizer:\n",
    "    def __init__(self, api_key=None, model=\"o3-mini-2025-01-31\"): # 사용하고자 하는 model 명시시 \n",
    "        \"\"\"초기화 함수\"\"\"\n",
    "        self.api_key = api_key or os.environ.get(\"OPENAI_API_KEY\")\n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"API 키가 필요합니다. 환경 변수 OPENAI_API_KEY를 설정하거나 직접 전달해주세요.\")\n",
    "        \n",
    "        openai.api_key = self.api_key\n",
    "        self.model = model\n",
    "        logger.info(f\"PDFSummarizer 초기화 완료 (모델: {model})\")\n",
    "    \n",
    "    def extract_text_from_pdf(self, file_path):\n",
    "        \"\"\"PDF 파일에서 텍스트를 추출하는 함수\"\"\"\n",
    "        if not os.path.exists(file_path):\n",
    "            logger.error(f\"파일을 찾을 수 없습니다: {file_path}\")\n",
    "            return \"\"\n",
    "        \n",
    "        try:\n",
    "            text = \"\"\n",
    "            with open(file_path, \"rb\") as file:\n",
    "                pdf_reader = PyPDF2.PdfReader(file)\n",
    "                for page_num, page in enumerate(pdf_reader.pages):\n",
    "                    page_text = page.extract_text() or \"\"\n",
    "                    text += page_text\n",
    "                    \n",
    "            # 텍스트가 너무 짧으면 경고\n",
    "            if len(text.strip()) < 100:\n",
    "                logger.warning(f\"추출된 텍스트가 매우 짧습니다: {file_path}\")\n",
    "                \n",
    "            return text\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"PDF 텍스트 추출 오류 ({file_path}): {str(e)}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def summarize_text(self, text, max_tokens=300, temperature=0.5, prompt_template=None):\n",
    "        \"\"\"텍스트 요약 함수 (ChatGPT API 활용)\"\"\"\n",
    "        if not text.strip():\n",
    "            logger.warning(\"요약할 텍스트가 없습니다.\")\n",
    "            return \"요약할 텍스트가 없습니다.\"\n",
    "        \n",
    "        # 기본 프롬프트 템플릿\n",
    "        default_template = \"다음 의학 텍스트를 요약해주세요. 주요 개념, 중요 용어, 핵심 내용을 포함하세요:\\n\\n{text}\\n\\n요약:\"\n",
    "        prompt = (prompt_template or default_template).format(text=text)\n",
    "        \n",
    "        # API 호출 시도 (오류 시 최대 3번 재시도)\n",
    "        max_retries = 3\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = openai.chat.completions.create(\n",
    "                    model=self.model,\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                    max_tokens=max_tokens,\n",
    "                    temperature=temperature\n",
    "                )\n",
    "                return response.choices[0].message.content.strip()\n",
    "            \n",
    "            except Exception as e:\n",
    "                logger.warning(f\"API 호출 오류 (시도 {attempt+1}/{max_retries}): {str(e)}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(2 ** attempt)  # 지수 백오프\n",
    "                else:\n",
    "                    logger.error(f\"API 호출 실패: {str(e)}\")\n",
    "                    return f\"요약 실패: {str(e)[:100]}...\"\n",
    "    \n",
    "    def process_single_pdf(self, file_path, max_tokens=300, temperature=0.5, prompt_template=None):\n",
    "        \"\"\"단일 PDF 파일 처리\"\"\"\n",
    "        file_name = os.path.basename(file_path)\n",
    "        logger.info(f\"파일 처리 시작: {file_name}\")\n",
    "        \n",
    "        text = self.extract_text_from_pdf(file_path)\n",
    "        \n",
    "        # 텍스트가 너무 길면 청크로 나누기\n",
    "        if len(text) > 10000:\n",
    "            logger.info(f\"텍스트가 길어서 청크로 나누어 요약합니다: {file_name}\")\n",
    "            chunks = self._split_text(text)\n",
    "            chunk_summaries = []\n",
    "            \n",
    "            for i, chunk in enumerate(chunks):\n",
    "                logger.info(f\"청크 {i+1}/{len(chunks)} 요약 중...\")\n",
    "                chunk_summary = self.summarize_text(chunk, max_tokens=150, temperature=temperature)\n",
    "                chunk_summaries.append(chunk_summary)\n",
    "            \n",
    "            # 청크 요약들을 다시 한번 요약\n",
    "            combined_summary = \"\\n\\n\".join(chunk_summaries)\n",
    "            final_summary = self.summarize_text(\n",
    "                combined_summary, \n",
    "                max_tokens=max_tokens,\n",
    "                temperature=temperature,\n",
    "                prompt_template=\"다음은 텍스트의 부분 요약들입니다. 이것들을 하나의 일관된 요약으로 통합해주세요:\\n\\n{text}\\n\\n최종 요약:\"\n",
    "            )\n",
    "        else:\n",
    "            final_summary = self.summarize_text(\n",
    "                text, \n",
    "                max_tokens=max_tokens,\n",
    "                temperature=temperature,\n",
    "                prompt_template=prompt_template\n",
    "            )\n",
    "        \n",
    "        logger.info(f\"파일 처리 완료: {file_name}\")\n",
    "        return {\n",
    "            \"file_path\": file_path,\n",
    "            \"file_name\": file_name,\n",
    "            \"summary\": final_summary,\n",
    "            \"text_length\": len(text)\n",
    "        }\n",
    "    \n",
    "    def _split_text(self, text, max_chunk_size=5000, overlap=200):\n",
    "        \"\"\"긴 텍스트를 청크로 나누는 함수\"\"\"\n",
    "        chunks = []\n",
    "        start = 0\n",
    "        \n",
    "        while start < len(text):\n",
    "            end = min(start + max_chunk_size, len(text))\n",
    "            \n",
    "            # 문장 중간에 잘리지 않도록 조정\n",
    "            if end < len(text):\n",
    "                # 마침표, 줄바꿈 등으로 끝나는 위치 찾기\n",
    "                for sep in ['. ', '.\\n', '\\n\\n', '\\n', '. ', '? ', '! ']:\n",
    "                    pos = text.rfind(sep, start, end)\n",
    "                    if pos != -1:\n",
    "                        end = pos + len(sep)\n",
    "                        break\n",
    "            \n",
    "            chunks.append(text[start:end])\n",
    "            start = end - overlap  # 겹치는 부분 유지\n",
    "            \n",
    "        return chunks\n",
    "    \n",
    "    def summarize_pdfs_to_csv(self, pdf_files, output_csv, max_workers=4, max_tokens=300, temperature=0.5, prompt_template=None):\n",
    "        \"\"\"여러 PDF 파일을 처리하고 요약 결과를 저장하는 함수\"\"\"\n",
    "        if not pdf_files:\n",
    "            logger.warning(\"처리할 PDF 파일이 없습니다.\")\n",
    "            return\n",
    "        \n",
    "        results = []\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # 병렬 처리\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            futures = {\n",
    "                executor.submit(\n",
    "                    self.process_single_pdf, \n",
    "                    file_path, \n",
    "                    max_tokens, \n",
    "                    temperature,\n",
    "                    prompt_template\n",
    "                ): file_path for file_path in pdf_files\n",
    "            }\n",
    "            \n",
    "            # tqdm으로 진행률 표시\n",
    "            for future in tqdm(futures, desc=\"PDF 요약 진행 중\"):\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    results.append(result)\n",
    "                except Exception as e:\n",
    "                    file_path = futures[future]\n",
    "                    logger.error(f\"파일 처리 실패 ({file_path}): {str(e)}\")\n",
    "                    results.append({\n",
    "                        \"file_path\": file_path,\n",
    "                        \"file_name\": os.path.basename(file_path),\n",
    "                        \"summary\": f\"처리 실패: {str(e)[:100]}...\",\n",
    "                        \"text_length\": 0\n",
    "                    })\n",
    "        \n",
    "        # 결과 저장\n",
    "        df = pd.DataFrame(results)\n",
    "        \n",
    "        # 디렉토리 확인 및 생성\n",
    "        output_dir = os.path.dirname(output_csv)\n",
    "        if output_dir and not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "            \n",
    "        # CSV 저장\n",
    "        df.to_csv(output_csv, index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        logger.info(f\"요약 작업 완료: {len(results)}개 파일 처리됨 (소요시간: {elapsed_time:.2f}초)\")\n",
    "        logger.info(f\"결과가 {output_csv}에 저장되었습니다.\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "# 사용 예시\n",
    "if __name__ == \"__main__\":\n",
    "    # API 키 설정 (환경 변수에서 가져오거나 직접 지정)\n",
    "    API_KEY = \"Your-OpenAI-Key\"\n",
    "    \n",
    "    # PDF 파일 경로 설정\n",
    "    # pdf_dir = \"data/medical_papers/\"\n",
    "    pdf_dir = r\"C:\\Users\\inhag\\Desktop\\Paper\\yes\"\n",
    "    output_csv = \"results/summarized_medical_papers.csv\"\n",
    "    \n",
    "    # 디렉토리에서 모든 PDF 파일 찾기\n",
    "    pdf_files = []\n",
    "    if os.path.exists(pdf_dir):\n",
    "        pdf_files = [os.path.join(pdf_dir, f) for f in os.listdir(pdf_dir) if f.lower().endswith('.pdf')]\n",
    "    \n",
    "    # 없으면 직접 경로 지정\n",
    "    if not pdf_files:\n",
    "        pdf_files = [\n",
    "            \"path/to/your/file1.pdf\", \n",
    "            \"path/to/your/file2.pdf\"\n",
    "        ]\n",
    "    \n",
    "    # 요약 객체 생성 및 실행\n",
    "    summarizer = PDFSummarizer(api_key=API_KEY)\n",
    "    \n",
    "    # 의학 논문 맞춤형 프롬프트 템플릿\n",
    "    medical_prompt = \"\"\"\n",
    "    다음 의학 텍스트를 전문적이고 체계적으로 요약해주세요:\n",
    "    1. 주요 질환이나 상태\n",
    "    2. 연구 방법 및 결과\n",
    "    3. 중요한 의학 용어와 그 정의\n",
    "    4. 임상적 의의\n",
    "    \n",
    "    원문:\n",
    "    {text}\n",
    "    \n",
    "    요약:\n",
    "    \"\"\"\n",
    "    \n",
    "    # 실행\n",
    "    results_df = summarizer.summarize_pdfs_to_csv(\n",
    "        pdf_files=pdf_files,\n",
    "        output_csv=output_csv,\n",
    "        max_workers=4,  # 병렬 처리 워커 수\n",
    "        max_tokens=400,  # 요약 길이\n",
    "        temperature=0.3,  # 더 일관된 결과를 위해 낮은 온도\n",
    "        prompt_template=medical_prompt\n",
    "    )\n",
    "    \n",
    "    # 결과 미리보기\n",
    "    print(\"\\n요약 결과 미리보기:\")\n",
    "    print(results_df[[\"file_name\", \"summary\"]].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Chapter7-ohihPSxV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
